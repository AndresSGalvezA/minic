<p align="right">
2020-08-27
</p>
<p align="left">
Universidad Rafael Land√≠var </br> Compiladores Sec. 01
</p>

<p align="left">
Sergio Lara [1044418] </br> Andres G√°lvez [1024718]
</p>

<h1 align= "center"><b>Mini C#  üë®‚Äçüíª</b></h1>

<p align="center">
Mini Compilador de C# </br> 
</p>

<h3 align = "left">Analizador L√©xico</h3>
<img align="right" alt="GIF" src="https://i.pinimg.com/originals/e4/26/70/e426702edf874b181aced1e2fa5c6cde.gif" />
<p align="left">
Tomamos la l√≥gica de ir evaluando l√≠nea por l√≠nea el archivo de entrada.  Para poder identificar el formato de cada l√≠nea y separar esta en los diferentes tipos de tokens o errores que puede producir, utilizamos Expresiones Regulares (ER) de la librer√≠a Regex de C#.
</br> </br>
Primero analizamos la l√≠nea y verificamos que no se encuentra vac√≠a, si no lo est√°, pasa a ser una cadena de caracteres la cual evaluamos en nuestra ER; gracias a Regex, esta es capaz de separar y devolvernos fragmentos que encajan en la ER, pero al haber tantas variantes, sol√≠a confundir algunos tokens o errores por otros; por ejemplo, una cadena de texto (string), supongamos "hola ", cuando era evaluada, la ER nos devolv√≠a <"hola>  y <"> como token o errores por separado, por lo que dentro de la ER formamos grupos que tienen una jerarqu√≠a, para que ciertas partes de la ER tengan una mayor prioridad de hacer "match" antes que otras.
</br> </br>
Jerarquia de nuestra ER y su definici√≥n:
</br> </br>
1) Strings (""((\w)|(\s)|(\p{P})|(\p{S}))+"") </br> </br>
2) Comentarios de una sola linea (//((\w)|(\s)|(\p{P})|(\p{S}))+) </br></br>
3) N√∫meros </br>
 3.1) Exponenciales ([0-9]+[.][0-9]*(E|e)[+]?[0-9]+) </br>
 3.2) Hexadecimales (0(x|X)([0-9]|[a-fA-F])+) </br>
 3.3) Flotantes ([0-9]+[.][0-9]*) </br>
 3.4) Enteros ([0-9]+) </br> </br>
4) Error string incompleto (""((\w)|(\s)|(\p{P})|(\p{S}))+) </br> </br>
5) Identificadores/Reservadas ([a-zA-Z]((\w)|[_])*)) </br> </br>
6) Operadores </br>
 6.1) De agrupaci√≥n juntos [()]|[{}]|[\[\]] --> Se quito de la ER, la soluci√≥n se describir√° en Analizar() </br>
 6.2) De comparaci√≥n (<=|>=|==|!=|&&|[||]) </br>
 6.3) Matem√°ticos (Son un solo caracter) --> Se reconocen como error 8) y luego se identifican como Operador en getTypeToken(string) </br> </br>
7) Error '*/'   ([*][/]) </br> </br>
8) Caracteres de error ((\p{P}){1}|(\p{S}){1})
</br> </br>
A pesar de que con Regex somos capaces de clasificar y dividr por sub-grupos, aun existen tres tokens/errores que no han sido identificados: los comentarios multil√≠nea, si una cadena es identificador o palabra reservada y los operadores de agrupaci√≥n cuando vienen uno tras otro. </br>
Como funci√≥n principal utilizamos Analizar(), la cual recorre el archivo l√≠nea por l√≠nea y cuando encuentra un '/*' ignora la l√≠nea actual y las siguientes hasta encontrar un '*/', si no es encontrado estos dos caractes de esa manera cuando Analizar() llega al final del archivo, esta guarda la posici√≥n donde se encuentra el '/*' y emite un error EOF de un comentario.</br> </br>

Si la cadena no es un comentario multil√≠nea, entonces analizamos la cadena entrante y utilizamos el m√©todo Regex.Match(string) para encontrar cada sub-cadena que cumple con la ER; si el "match" es un operador de agrupaci√≥n de apertura '(', '[' o '{', guardamos en una variable temporal los datos de este caracter (index y caracter) para luego si el siguiente match es un operador de agrupaci√≥n de cierre se concatenen y sean analizados como un √∫nico token. </br> </br>
Luego, en la cadena a analizar, necesitamos saber qu√© tipo de token genera esta, el tipo de token se obtiene con el m√©todo getTypeToken(string), el cual devuelve el n√∫mero al que pertenece la cadena seg√∫n la jeraqu√≠a indicada anteriormente. </br>

Si el resultado de getTypeToken(string) indica que es un n√∫mero, se obtiene su valor y se procede a generar el token. </br>
Si el resultado es un Identificador/Reservada se analiza si la cadena es una palabra reservada o un identificador, para luego ser generado su respectivo token. </br>
Si no es ninguno de estos dos se manda a generar el token o error con el caracter que se esta analizando en ese momento.
</p>

<h3 align = "left">Analizador Sintactico Descendente Recursivo</h3>
<p align="left">
Para esta fase se ha utilizado la siguiente gramatica: </br>
https://docs.google.com/document/d/10RhYVMYsLzrrJKRTNNxrR2Z8TuBcNV2Q24yhxDdTG9I/edit?usp=sharing
</br></br>
La presente fase del compilador se trabaja sobre la una clase que recibe como parametro una lista de Tokens en orden conforme fueron encontrados y analizados por el Analizador lexico. Este objeto Token esta conformado por su Type, que indica si es operador, palabra reservada, constante o identificador. content que es el contenido del token, numLinea que representa el numero de linea donde se encontraba este token; y typeConst que indica que tipo de constante es este token, cuando no es una constante este campo se encuentra como una cadena vacia
</br></br>
El analizador Sintactivo funciona ingresando a cada producci√≥n segun sea el orden en la gramatica y cuando en la gramatica encuentra un simbolo terminal este compara que el token en la posici√≥n [0] de la lista de Tokens sea el mismo ST y si este es procede a consumir el token y eliminarlo de la lista Tokens, y luego procede a almacenar este en una lista temporal de token (tmpTokens).
</br></br>
Se ha creado una funci√≥n por cada producci√≥n de tipo string. Cada funcion es capaz de devolver cinco tipos de retroalimentaci√≥n a si mismo para poder ejecutar el analisis correctamente, las posibles respuestas son:
* "work", significa que la actual producci√≥n ha resultado correcta
* "error", significa que se ha encontrado un error de lexico
* "error###", indica que se ha ingresado a un posible error no controlado
* "cero", significa que la lista Tokens se encuentra vacia.
* "epsilon", significa que la cadena es aceptable que no se encuentre
</br></br>
Cuando se encuentra que una producci√≥n ha retornado error, el analizador lexico ingresa a la siguiente producci√≥n correspondiente del mismo nivel y si algun token ha sido consumido durante el analisis anterior, se procede a integrar los tokens eliminados almacenados en tmpTokens de nuevo a la lista Tokens realizando asi un Backtraking hacia la ultima cadena de tokens correcta. Luego tmpTokens se vuelve a su estado inicial para se utilizada una proxima vez si es necesario.
</br></br>
Si el Analizador Sintactico sigue revisando producciones cuando ya no se encuentran tokens, este solo verifica que el resultado sea "epsilon" o si regresa a la producci√≥n Decl o Program este verifica que si aun existen tokens por lo que si ya no hay se para el analisis. 
</p>